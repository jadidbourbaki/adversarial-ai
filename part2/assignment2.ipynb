{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Assignment 2: Neural Network Architecture and Optimization\n",
    "\n",
    "In this assignment, you will implement and experiment with different neural network architectures for MNIST digit classification. Building on the concepts from Recitation 2, you'll explore how architecture choices affect performance and prepare models for adversarial testing.\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "1. Complete all exercises in this notebook\n",
    "2. Ensure all code runs without errors\n",
    "3. Include written responses where requested\n",
    "4. Save your best model for use in Part 4\n",
    "5. Submit the completed notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup\n",
    "\n",
    "Run the following code to set up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load MNIST data (you may reuse code from recitation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders with batch_size=64\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(\"âœ… Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 1: Architecture Comparison \n",
    "\n",
    "Compare different CNN architectures and analyze their performance trade-offs.\n",
    "\n",
    "You will implement three different architectures:\n",
    "1. **SimpleNet**: A minimal CNN (2 conv layers)\n",
    "2. **MediumNet**: A balanced CNN (similar to recitation)  \n",
    "3. **DeepNet**: A deeper CNN (4+ conv layers)\n",
    "\n",
    "For each architecture, measure:\n",
    "- Training time per epoch\n",
    "- Final test accuracy\n",
    "- Number of parameters\n",
    "- Memory usage\n",
    "\n",
    "### Part A: Implement SimpleNet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN with minimal layers for MNIST classification.\n",
    "    \n",
    "    Architecture Requirements:\n",
    "    - 2 convolutional layers\n",
    "    - 1 fully connected layer (plus output layer)\n",
    "    - Use ReLU activations and max pooling\n",
    "    - Aim for < 50,000 parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        # TODO: Implement a simple CNN architecture\n",
    "    # TODO: Implement your solution here\n",
    "        \n",
    "        # TODO: Define your layers here\n",
    "        # Hint: Start with nn.Conv2d(1, ...) for grayscale input\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "    # TODO: Implement your solution here\n",
    "        \n",
    "        # TODO: Implement your forward pass here\n",
    "        pass\n",
    "\n",
    "simple_model = SimpleNet().to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in simple_model.parameters())\n",
    "print(f\"SimpleNet - Total parameters: {total_params:,}\")\n",
    "print(f\"Model summary:\\n{simple_model}\")\n",
    "\n",
    "# Test with dummy input\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "with torch.no_grad():\n",
    "    dummy_output = simple_model(dummy_input)\n",
    "    print(f\"Output shape: {dummy_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Part B: Implement DeepNet\n",
    "\n",
    "Create a deeper network with 4+ convolutional layers. Pay attention to managing the spatial dimensions as you add more layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep CNN with 4+ convolutional layers for MNIST classification.\n",
    "    \n",
    "    Architecture Requirements:\n",
    "    - At least 4 convolutional layers\n",
    "    - Use batch normalization to help training\n",
    "    - Include dropout for regularization\n",
    "    - Manage spatial dimensions carefully\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DeepNet, self).__init__()\n",
    "        \n",
    "        # TODO: Implement a deep CNN architecture\n",
    "    # TODO: Implement your solution here\n",
    "        \n",
    "        # TODO: Define your deep architecture here\n",
    "        # Hint: Use batch normalization: nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "    # TODO: Implement your solution here\n",
    "        \n",
    "        # TODO: Implement your forward pass here\n",
    "        pass\n",
    "\n",
    "deep_model = DeepNet().to(device)\n",
    "\n",
    "\n",
    "deep_params = sum(p.numel() for p in deep_model.parameters())\n",
    "print(f\"DeepNet - Total parameters: {deep_params:,}\")\n",
    "\n",
    "# Test forward pass\n",
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "with torch.no_grad():\n",
    "    dummy_output = deep_model(dummy_input)\n",
    "    print(f\"Output shape: {dummy_output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Part C: Architecture Comparison Analysis \n",
    "\n",
    "Train all three models and compare their performance. Create a comparison table and discuss the trade-offs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=3):\n",
    "    \"\"\"Train model and return metrics.\"\"\"\n",
    "    model.train()\n",
    "    history = {'loss': [], 'accuracy': [], 'time': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for data, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        \n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['accuracy'].append(epoch_acc)\n",
    "        history['time'].append(epoch_time)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Loss={epoch_loss:.4f}, Acc={epoch_acc:.2f}%, Time={epoch_time:.1f}s')\n",
    "    \n",
    "    return history\n",
    "    pass\n",
    "\n",
    "models = {\n",
    "    'SimpleNet': simple_model,\n",
    "    'DeepNet': deep_model,\n",
    "    # Add MediumNet from recitation if you want\n",
    "}\n",
    "\n",
    "results = {}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    history = train_model(model, train_loader, criterion, optimizer, num_epochs=2)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    avg_epoch_time = np.mean(history['time'])\n",
    "    \n",
    "    results[name] = {\n",
    "        'test_accuracy': test_acc,\n",
    "        'parameters': params,\n",
    "        'avg_epoch_time': avg_epoch_time,\n",
    "        'final_train_acc': history['accuracy'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"Final test accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Exercise 2: Model Analysis\n",
    "\n",
    "Let's analyze your best model's performance, identify failure cases, and prepare for adversarial testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify which digits your model struggles with most and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change this to your best model, or keep the deep_model\n",
    "best_model = deep_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "best_model.eval()\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        outputs = best_model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix - Best Model')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_targets, all_predictions, \n",
    "                          target_names=[str(i) for i in range(10)]))\n",
    "\n",
    "# Analyze most confused pairs\n",
    "print(\"\\nMost Confused Digit Pairs:\")\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j and cm[i][j] > 20:  # Threshold for significant confusion\n",
    "            print(f\"True {i} predicted as {j}: {cm[i][j]} times ({cm[i][j]/cm[i].sum()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the worst performing examples are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_worst_examples(model, dataset, num_examples=12):\n",
    "    \"\"\"Find examples where model is most confident but wrong.\"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # TODO: Implement your solution here\n",
    "    pass\n",
    "\n",
    "worst_cases = find_worst_examples(best_model, test_dataset)\n",
    "\n",
    "if worst_cases:\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "    fig.suptitle('Worst Predictions (High Confidence, Wrong Answer)', fontsize=16)\n",
    "    \n",
    "    for i, case in enumerate(worst_cases):\n",
    "        if i >= 12:\n",
    "            break\n",
    "        row, col = i // 4, i % 4\n",
    "        \n",
    "        image_np = case['image'].squeeze().numpy()\n",
    "        axes[row, col].imshow(image_np, cmap='gray')\n",
    "        title = f\"True: {case['true_label']}, Pred: {case['predicted_label']}\\nConf: {case['confidence']:.2f}\"\n",
    "        axes[row, col].set_title(title, color='red', fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Found {len(worst_cases)} high-confidence wrong predictions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ‰ Assignment Complete!\n",
    "\n",
    "Next Steps\n",
    "\n",
    "Your trained model is now ready for **Adversarial Attacks**, where you will generate adversarial examples to fool your classifier.\n",
    "\n",
    "**Save your work and prepare for the exciting world of adversarial machine learning!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}